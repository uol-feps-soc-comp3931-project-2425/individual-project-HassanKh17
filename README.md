# Pose Estimation Pipeline for Surgical Tools

This repository implements a modular deep learning pipeline for 6D pose estimation of surgical tools using a modified PoseCNN architecture. The system is built for reproducibility, clear validation, and visual transparency. It is designed for applications in robotic-assisted surgery, where precise localisation of instruments is critical.

---

## ğŸ§  Project Overview

The goal is to estimate the 6D pose â€” 3D translation and 3D rotation â€” of surgical tools from monocular RGB images. This pipeline:

- Accepts RGB + binary mask images as input
- Converts 3x4 pose matrices into quaternion-translation pairs
- Trains a CNN with dual regression heads
- Evaluates performance using geometric and visual metrics
- Validates annotations and rotation representations

It is tailored for datasets with annotated pose matrices, camera intrinsics, and object models.

---

## ğŸ—‚ Directory Structure

```bash
pose_estimation_project/
â”œâ”€â”€ data/                    # Dataset and loading utilities
â”‚   â”œâ”€â”€ dataloader.py        # Custom PyTorch Dataset class
â”‚   â””â”€â”€ utils.py             # Preprocessing, augmentation (if added)
â”œâ”€â”€ model/                   # Model definition and losses
â”‚   â”œâ”€â”€ posecnn.py           # Main CNN model
â”‚   â””â”€â”€ loss_functions.py    # Quaternion loss + translation MSE
â”œâ”€â”€ training/                # Training and evaluation logic
â”‚   â”œâ”€â”€ train.py             # Train loop
â”‚   â””â”€â”€ metrics.py           # ADD, ADD-S, 2D Projection error
â”œâ”€â”€ visualisation/           # Drawing and debugging tools
â”‚   â”œâ”€â”€ draw_pose.py         # Overlay pose axes and keypoints
â”‚   â””â”€â”€ vis_utils.py         # (Optional) utils for mask/contour visualisation
â”œâ”€â”€ validation/              # Standalone integrity checkers
â”‚   â”œâ”€â”€ verify_pose_integrity.py     # Checks .npy matrices
â”‚   â””â”€â”€ verify_annotations_json.py   # Confirms unit quaternion annotations
â”œâ”€â”€ utils/                   # Output manager and helper functions
â”‚   â””â”€â”€ output_manager.py
â”œâ”€â”€ outputs/                 # Saved logs, models, and figures
â”œâ”€â”€ run.py                   # Unified launcher script
â”œâ”€â”€ requirements.txt         # Dependency list
â””â”€â”€ README.md                # This file
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/uol-feps-soc-comp3931-project-2425/individual-project-HassanKh17.git
cd individual-project-HassanKh17
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```
You may use a virtual environment for isolation.

### 3. Prepare Your Dataset
Structure your training data as follows:
```
MFB_TRAIN/TRAIN/
â”œâ”€â”€ image_resized/             # RGB images
â”œâ”€â”€ mask/                      # Binary masks
â”œâ”€â”€ pose/                      # .npy pose files (3x4 matrices)
â”œâ”€â”€ posecnn_annotations.json   # Converted JSON with translation + quaternion
â”œâ”€â”€ model_keypoints.npy        # 3D object keypoints
â”œâ”€â”€ camera_matrix.npy          # Intrinsic matrix (3x3)
```

### 4. Launch Training + Evaluation
```bash
python run.py
```
This executes:
- Model training on annotated RGB+mask images
- Visualisation of predicted pose overlays
- Evaluation using ADD, ADD-S, 2D projection error
- Saves results under `outputs/` automatically

---

## ğŸ§ª Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **ADD**      | Mean distance between model points transformed by predicted and GT pose |
| **ADD-S**    | ADD with symmetry-aware closest point matching |
| **2D Projection Error** | Average pixel distance of keypoint projections |

Additional metrics or plots (e.g., quaternion norm histograms) are supported via validation scripts.

---

## ğŸ§¹ Validation Tools

Standalone scripts for input integrity:

```bash
# Check pose matrices (rank + orthogonality)
python validation/verify_pose_integrity.py --dir MFB_TRAIN/TRAIN/pose

# Check that quaternions are unit vectors
python validation/verify_annotations_json.py --json MFB_TRAIN/TRAIN/posecnn_annotations.json
```

Outputs: pass/fail logs for traceability.

---

## ğŸ–¼ Visualisations

Pose overlays are saved to:
```
outputs/<experiment_name>/visualisations/
```
Includes:
- RGB + axis overlay
- Projected keypoints
- Side-by-side examples

---

## ğŸ§¾ Logging and Output
All results are automatically structured:
```
outputs/
â””â”€â”€ posecnn_experiment_YYYYMMDD_HHMM/
    â”œâ”€â”€ checkpoints/
    â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ training_log.jsonl
    â”œâ”€â”€ visualisations/
    â””â”€â”€ evaluation_results.json
```
Use `OutputManager` in `utils/` for flexible saving.

---

## âš™ï¸ Configuration
Modify `run.py` to change:
- Dataset paths
- Object diameter
- Camera intrinsics
- Experiment parameters

---


